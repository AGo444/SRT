<?xml version="1.0"?>
<Container version="2">
  <Name>WhisperX Subtitle Creator and Translator</Name>
  <Repository>agoddrie/whisperx-translator</Repository>
  <Registry>https://hub.docker.com/r/agoddrie/whisperx-translator</Registry>
  <Version>1.2</Version>
  <Platform>linux/amd64,linux/arm64</Platform>
  <Branch>main</Branch>
  <Network>bridge</Network>
  <Privileged>false</Privileged>
  <WebUI></WebUI>
  <Shell>sh</Shell>
  
  <Beta>false</Beta>
  <Project>https://github.com/AGo444/SRT</Project>
  <Support>https://github.com/AGo444/SRT/issues</Support>
  <Icon>https://raw.githubusercontent.com/AGo444/SRT/master/icon.png</Icon>
  <Category>Tools: MediaServer:Video</Category>
  
  <TemplateURL>https://raw.githubusercontent.com/AGo444/SRT/master/my-whisperx-translator-gpu.xml</TemplateURL>
  <Networking>
    <Mode>bridge</Mode>
    <Dns1>8.8.8.8</Dns1>
    <Dns2>8.8.4.4</Dns2>
  </Networking>

  <Config Name="Input Directory" Target="/data" Default="" Mode="rw" Description="Path to your video files" Type="Path" Display="always" Required="true" Mask="false">/mnt/user/YourVideoShare/</Config>

  <Config Name="Target Language" Target="TARGET_LANGUAGE" Default="nl" Mode="list" Description="Select target language for subtitles" Type="Variable" Display="always" Required="true" Mask="false">nl|de|fr|es|it</Config>

  <Config Name="WhisperX Model" Target="WHISPERX_MODEL" Default="large-v3" Mode="list" Description="WhisperX model to use" Type="Variable" Display="always" Required="true" Mask="false">large-v3|large-v2|medium</Config>

  <Config Name="Debug Mode" Target="DEBUG" Default="0" Mode="list" Description="Enable debug logging" Type="Variable" Display="advanced" Required="false" Mask="false">0|1</Config>

  <Config Name="Use CUDA" Target="USE_CUDA" Default="1" Mode="list" Description="Enable CUDA GPU support" Type="Variable" Display="advanced" Required="false" Mask="false">0|1</Config>

  <Config Name="Batch Size" Target="BATCH_SIZE" Default="8" Mode="integer" Description="Processing batch size (lower for less memory)" Type="Variable" Display="advanced" Required="false" Mask="false"></Config>

  <Config Name="Python Unbuffered" Target="PYTHONUNBUFFERED" Default="1" Mode="integer" Description="Force Python output unbuffering" Type="Variable" Display="advanced" Required="false" Mask="false"></Config>

  <Config Name="NVIDIA Visible Devices" Target="NVIDIA_VISIBLE_DEVICES" Default="all" Mode="string" Description="GPU devices to use (all/0,1,etc)" Type="Variable" Display="advanced" Required="false" Mask="false"></Config>

  <!-- Add GPU requirements -->
  <ExtraParams>--runtime=nvidia --dns 8.8.8.8 --dns 8.8.4.4</ExtraParams>
  <DonateText>If you find this container useful, consider supporting the project on GitHub</DonateText>
  <DonateLink>https://github.com/AGo444/SRT</DonateLink>
  <Description>WhisperX subtitle generator and translator with GPU support. Automatically creates English subtitles and translates them to your preferred language.</Description>
  
  <!-- Add memory limits -->
  <Memory>8192</Memory>
  <MemorySwap>12288</MemorySwap>

  <!-- Add health check -->
  <HealthCheck>
    <Test>["CMD-SHELL", "python3 -c 'import torch; print(\"GPU available:\", torch.cuda.is_available())' || exit 1"]</Test>
    <Interval>30s</Interval>
    <Timeout>10s</Timeout>
    <Retries>3</Retries>
    <StartPeriod>5s</StartPeriod>
  </HealthCheck>

  <!-- Add extra environment variables -->
  <Config Name="Cache Directory" Target="CACHE_DIR" Default="/config/cache" Mode="rw" Description="Cache directory for models" Type="Path" Display="advanced" Required="false" Mask="false">/mnt/user/appdata/whisperx/cache</Config>

  <Config Name="Max Memory" Target="MAX_MEMORY" Default="8192" Mode="integer" Description="Maximum memory usage in MB" Type="Variable" Display="advanced" Required="false" Mask="false"></Config>

  <Config Name="Num Threads" Target="NUM_THREADS" Default="4" Mode="integer" Description="Number of CPU threads to use" Type="Variable" Display="advanced" Required="false" Mask="false"></Config>

  <Data>
    <Volume>
      <HostDir>/mnt/user/YourVideoShare/</HostDir>
      <ContainerDir>/data</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
    <!-- Add additional volume for cache -->
    <Volume>
      <HostDir>/mnt/user/appdata/whisperx/cache</HostDir>
      <ContainerDir>/config/cache</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
  </Data>
</Container>
